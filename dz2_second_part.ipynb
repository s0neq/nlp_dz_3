{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### дз 2(2я часть - сравнение качества работы программы из 1го дз с ф-ей, выделяющей биграммы) \n",
    "\n",
    "### Генералова Софья 182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "примерно в пропорции 25% (125+ 125-) тестовые, 75% (375+ 375-) тренинг\n",
    "\n",
    "с одного фильма - 1 полож отзыв, 1 отриц отзыв в тестовый дикт и так же в тренинговый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import os\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "import random, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unofficial api kinopoisk\n",
    "https://kinopoiskapiunofficial.tech/documentation/api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = set([3, 19, 17, 16, 7, 6, 13, 22, 8, 23, 10, 11, 4, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = '2d63343e-b155-47b6-8d01-548bdd7f7902'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_movies(genre, page=1):\n",
    "    data = requests.get(\n",
    "        'https://kinopoiskapiunofficial.tech/api/v2.1/films/search-by-filters', \n",
    "        params={\n",
    "            \"genre\": genre, #1,  # action\n",
    "            \"page\":page,\n",
    "        },\n",
    "    \n",
    "        headers={\n",
    "            \"X-API-KEY\": TOKEN,\n",
    "        }\n",
    "    \n",
    "    ).json()\n",
    "    \n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### собирает айди"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids(some_d, what, tr_p=True, test_p=True, tr_n=True, test_n=True, range_st=1):\n",
    "    if what == 'f': # для фильма\n",
    "        for film in some_d['films']:\n",
    "            ids_set.add(film[\"filmId\"])\n",
    "    elif what == 'r': # для отзыва\n",
    "        for rev in some_d['reviews']:\n",
    "            if not (tr_p or test_p or tr_n or test_n): # если на этот фильм уже собрано 4 отзыва\n",
    "                break\n",
    "            if rev['reviewType'] == 'POSITIVE':\n",
    "                if tr_p: # если еще нет полож отзыва для обучения\n",
    "                    ids_dict_r[rev['reviewType']].add(rev[\"reviewId\"])\n",
    "                    tr_p = False\n",
    "                elif test_p: # если еще нет полож отзыва для теста\n",
    "                    test_ids_dict_r[rev['reviewType']].add(rev[\"reviewId\"])\n",
    "                    test_p = False\n",
    "                    \n",
    "            elif rev['reviewType'] == 'NEGATIVE':\n",
    "                if tr_n: # если еще нет отриц отзыва для обучения\n",
    "                    ids_dict_r[rev['reviewType']].add(rev[\"reviewId\"])\n",
    "                    tr_n = False\n",
    "                elif test_n: # если еще нет отриц отзыва для теста\n",
    "                    test_ids_dict_r[rev['reviewType']].add(rev[\"reviewId\"])\n",
    "                    test_n = False\n",
    "        \n",
    "        if tr_p or test_p or tr_n or test_n: # если какого-то типа отзывов не было\n",
    "            manyRevs = some_d['pagesCount']\n",
    "            if manyRevs: # чтобы не попался фильм у которого все поля null (id фильма 745552)\n",
    "                if manyRevs > 1 and range_st < manyRevs: # если стр больше одной\n",
    "                    range_st += 1\n",
    "                    get_ids(get_rev_ids(some_d['filmId'], range_st), 'r', tr_p, test_p, tr_n, test_n, range_st)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dict_r = {'NEGATIVE': set(), 'POSITIVE': set()} # dict for training\n",
    "test_ids_dict_r = {'NEGATIVE': set(), 'POSITIVE': set()} # dict for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_set = set() # set for films ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### достает список айди отзывов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rev_ids(film_id, page=1):\n",
    "    data = requests.get(\n",
    "        'https://kinopoiskapiunofficial.tech/api/v1/reviews',\n",
    "        params={\n",
    "            \"filmId\": film_id,\n",
    "            \"page\":page,\n",
    "        },\n",
    "    \n",
    "        headers={\n",
    "            \"X-API-KEY\": TOKEN,\n",
    "        }\n",
    "    \n",
    "    ).json()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### достает текст отзыва по его айди"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rev(rev_id):\n",
    "    data = requests.get(\n",
    "        'https://kinopoiskapiunofficial.tech/api/v1/reviews/details', \n",
    "        params={\n",
    "            \"reviewId\": rev_id,\n",
    "        },\n",
    "    \n",
    "        headers={\n",
    "            \"X-API-KEY\": TOKEN,\n",
    "        }\n",
    "    \n",
    "    ).json()\n",
    "    \n",
    "    rev_text = data['reviewDescription']\n",
    "    \n",
    "    return rev_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(\n",
    "        'https://kinopoiskapiunofficial.tech/api/v2.1/films/search-by-filters', \n",
    "        params={\n",
    "            \"genre\": 1, #1,  # action\n",
    "            \"page\":1,\n",
    "        },\n",
    "    \n",
    "        headers={\n",
    "            \"X-API-KEY\": TOKEN,\n",
    "        }\n",
    "    \n",
    "    ).json()['pagesCount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### достать айди отзывов по айди фильмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_r(ids_set):\n",
    "    for film_id in ids_set: # распаковка отзывов на эти фильмы\n",
    "        revs = get_rev_ids(film_id)\n",
    "        get_ids(revs, 'r')\n",
    "    ids_set = set() # убрать айди фильмов кот уже проверены\n",
    "    return ids_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### скачивание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre 2 added\n",
      "genre 3 added\n",
      "genre 4 added\n",
      "genre 6 added\n",
      "genre 7 added\n",
      "genre 8 added\n",
      "genre 10 added\n",
      "genre 11 added\n",
      "genre 13 added\n",
      "genre 16 added\n",
      "genre 17 added\n",
      "genre 19 added\n",
      "genre 22 added\n"
     ]
    }
   ],
   "source": [
    "for genre in genres:\n",
    "    # проверка кол-ва отзывов\n",
    "    if len(ids_dict_r['NEGATIVE']) < 375 or len(ids_dict_r['POSITIVE']) < 375 or len(test_ids_dict_r['NEGATIVE']) < 125 or len(test_ids_dict_r['POSITIVE']) < 125:\n",
    "        list_of_m = get_list_of_movies(genre)\n",
    "        if not list_of_m:\n",
    "            print(genre)\n",
    "        manyPages = list_of_m['pagesCount']\n",
    "#         print(type(manyPages), manyPages)\n",
    "        get_ids(list_of_m, 'f')\n",
    "        ids_set = g_r(ids_set)\n",
    "        \n",
    "        if manyPages > 1:\n",
    "            for i in range(2, manyPages+1):\n",
    "                get_ids(get_list_of_movies(genre, i), 'f')\n",
    "                ids_set = g_r(ids_set)\n",
    "                    \n",
    "        print('genre', genre, 'added')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753\n",
      "403\n",
      "710\n",
      "285\n"
     ]
    }
   ],
   "source": [
    "print(len(ids_dict_r['POSITIVE']))\n",
    "print(len(ids_dict_r['NEGATIVE']))\n",
    "print(len(test_ids_dict_r['POSITIVE']))\n",
    "print(len(test_ids_dict_r['NEGATIVE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### видимо на некоторые фильмы вообще нет отрицательных отзывов, положительных собралось больше. поэтому убираю лишние айди:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids_dict_r['POSITIVE'] = set(list(test_ids_dict_r['POSITIVE'])[:285])\n",
    "ids_dict_r['POSITIVE'] = set(list(ids_dict_r['POSITIVE'])[:403])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### теперь все более менее одинаково"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n",
      "403\n",
      "285\n",
      "285\n"
     ]
    }
   ],
   "source": [
    "print(len(ids_dict_r['POSITIVE']))\n",
    "print(len(ids_dict_r['NEGATIVE']))\n",
    "print(len(test_ids_dict_r['POSITIVE']))\n",
    "print(len(test_ids_dict_r['NEGATIVE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# добавляю выделение синт. групп"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_syntax_phrases(text):\n",
    "    tokens = []\n",
    "    doc = Doc(text)\n",
    "    doc.segment(segmenter) # tokenization\n",
    "    doc.tag_morph(morph_tagger) # pos tagging\n",
    "    doc.parse_syntax(syntax_parser) # syntax tagging\n",
    "    h_id = None # переменная куда я буду записывать айди вершины для не\n",
    "    ne = ''\n",
    "    for i in range(len(doc.tokens)):\n",
    "        r_t = doc.tokens[i].text\n",
    "        \n",
    "        if r_t == 'не':\n",
    "            ne = r_t\n",
    "            h_id = doc.tokens[i].head_id\n",
    "            continue\n",
    "        if h_id:\n",
    "            # если айди элемента совп с айди вершины для не и часть речи подходит\n",
    "            if doc.tokens[i].id == h_id and doc.tokens[i].pos in ['ADV', 'VERB', 'ADJ']:\n",
    "                res = ne + ' ' + doc.tokens[i].text\n",
    "                tokens.append(res)\n",
    "                h_id = None\n",
    "                ne = ''\n",
    "            else:\n",
    "                tokens.append(doc.tokens[i].text)\n",
    "        else:\n",
    "            tokens.append(doc.tokens[i].text)\n",
    "    if ne != '': # если было не, но не было вершины\n",
    "        tokens.append(ne)\n",
    "  \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### каунтер на основе токенизированных и лемматизированных отзывов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_com_w(c_type, ids):\n",
    "    for rev_id in ids:\n",
    "        rev_text = get_rev(rev_id)\n",
    "        t = rev_text.lower()\n",
    "        tokens = find_syntax_phrases(t) # выдел токенов в том числе синт групп\n",
    "#         tokens = nltk.word_tokenize() # tokenization\n",
    "        for t in tokens:\n",
    "            if t.isalpha():\n",
    "                norm_form = morph.parse(t)[0].normal_form # lemmatization\n",
    "                c_type[norm_form]+=1\n",
    "    return c_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### по каунтеру для негативных и для позитивных отзывов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_neg = most_com_w(Counter(), ids_dict_r['NEGATIVE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_pos = most_com_w(Counter(), ids_dict_r['POSITIVE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "словари из каунтеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_n = dict(c_neg)# .most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_p = dict(c_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15850 15913\n"
     ]
    }
   ],
   "source": [
    "print(len(mc_n), len(mc_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "множества из слов, отсекая частотности равные 1 или 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_n_set = set(el for el in mc_n if mc_n[el] > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_p_set = set(el for el in mc_p if mc_p[el] > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5395 5532\n"
     ]
    }
   ],
   "source": [
    "print(len(mc_n_set), len(mc_p_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "удаляю пересечения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_set = mc_n_set & mc_p_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_n_set -= del_set\n",
    "mc_p_set -= del_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795 1932\n"
     ]
    }
   ],
   "source": [
    "print(len(mc_n_set), len(mc_p_set))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Создайте функцию, которая будет определять, положительный ли отзыв или отрицательный в зависимости от того, какие слова встретились в нём, и посчитайте качество при помощи accuracy (1 - за коректно работающую функцию, 1 - за подсчёт accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### на основе непересекающихся множеств с фильтром по частотности 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_or_neg_check(test):\n",
    "    negcount = 0\n",
    "    poscount = 0\n",
    "    tokens = nltk.word_tokenize(test.lower())\n",
    "#     print(tokens) # tokenization\n",
    "    for t in tokens:\n",
    "        if t.isalpha():\n",
    "            norm_form = morph.parse(t)[0].normal_form\n",
    "            if norm_form in mc_n_set:\n",
    "                negcount += 1\n",
    "#                 print(norm_form)\n",
    "            elif norm_form in mc_p_set:\n",
    "                poscount += 1\n",
    "#                 print(norm_form)\n",
    "    if negcount > poscount:\n",
    "        \n",
    "#         print('NEGATIVE')\n",
    "#         print(negcount, poscount)\n",
    "        return 'NEGATIVE'\n",
    "    else:\n",
    "#         print('POSITIVE')\n",
    "#         print(negcount, poscount)\n",
    "        return 'POSITIVE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_check(test_ids_dict_r):\n",
    "    results = []  # сюда будем писать результаты\n",
    "    gold = []     # сюда будем писать исходный язык\n",
    "    for typ in test_ids_dict_r:\n",
    "        for rev_id in test_ids_dict_r[typ]:\n",
    "            rev_text = get_rev(rev_id) # получить текст отзыва по айди\n",
    "            predicted_type = pos_or_neg_check(rev_text)\n",
    "            results.append(predicted_type)\n",
    "            gold.append(typ)\n",
    "            \n",
    "    print(\"RESULTS:\")\n",
    "    print(\"Test size: %d texts per negative review type\" % len(test_ids_dict_r['NEGATIVE']))\n",
    "    print(\"Test size: %d texts per positive review type\" % len(test_ids_dict_r['POSITIVE']))\n",
    "    print(\"Accuracy: %.4f\" % accuracy_score(results, gold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# с наташей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS:\n",
      "Test size: 285 texts per negative review type\n",
      "Test size: 285 texts per positive review type\n",
      "Accuracy: 0.7123\n"
     ]
    }
   ],
   "source": [
    "accuracy_check(test_ids_dict_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# предыдущий результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS:\n",
      "Test size: 285 texts per negative review type\n",
      "Test size: 285 texts per positive review type\n",
      "Accuracy: 0.6877\n"
     ]
    }
   ],
   "source": [
    "accuracy_check(test_ids_dict_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# результаты:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "было 0.6877, стало 0.7123\n",
    "качество улучшилось, но не сильно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
